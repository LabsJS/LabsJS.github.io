---
title : "Deep Anomaly Detection (3)"
excerpt : "Model"
toc: true
toc_sticky: true
categories :	
 - Deep Learning
 - Anomaly Detection
---

> 본 포스팅에서는 이상 탐지 조사 논문[^1] 을 참고 하여,
> Deep Anomaly Detection (DAD) 모델을 레이블의 가용성 (availability of labels), 학습 objective로 나눠서 다룬다



## 1. Supervised Deep Anomaly Detection

Supervised DAD는 레이블 된 데이터 인스턴스 세트에서 **seperating boundary** (분리 경계)를 학습하고, <br/>
학습된 모델로 테스트 인스턴스를 정상 또는 이상 클래스 중 하나로 분류한다. 

**Assumptions** 

다중 클래스 분류 기반 이상 탐지 기술은 학습 데이터가 여러 개의 정상 클래스 레이블 인스턴스를 포함한다고 가정한다. 이는 다른 클래스에서 이상 클래스를 구분하기 위해 분류자 (classifier) 를 학습한다. <br/>
일반적으로, 이상 탐지에서  지도 학습 기반 딥러닝 분류 시스템은 **1. 피쳐 추출 네트워크**와 **2.분류자 네트워크** 두 개를 사용한다. 좋은 성능을 위해서는 많은 데이터가 필요하다, **실제로는 레이블된 데이터를 구하기가 어렵다**. 때문에 이 방식은 자주 사용되지 않는다.

**Computational Complexity** 

Supervised DAD 기반 기술의 계산 복잡도는 입력 데이터의 차원과 backpropagation 알고리즘으로 학습되는 hidden layer의 수에 의존적이다.  계산 복잡도는 hidden layer 수에 비례하여 선형적으로 증가한다.

**Advantages**

- 좋은 성능 (정확도)
- 빠른 test 속도: test 단계에서 사전 계산된 모델과 각 테스트 인스턴스를 비교

**Disadvantages**

- 데이터 부족
- 데이터의 feature space 가 복잡한 경우, 학습이 어려움



## 2. Semi-supervised Deep Anomaly Detection

Semi-supervised DAD 기술은 모든 학습 인스턴스가 하나의 클래스 레이블만 가진다는 가정으로 작동한다. DAD 기술은 정상 인스턴스 주변에 분리 경계를 학습한다. 대다수 클래스에 속하지 않는, 테스트 인스턴스는 이상으로 지정된다.

**Assumptions** 

Semi-supervised DAD 방법은 데이터 인스턴스에 대한 anomaly 점수를 부여하기 위해 다음 중 하나의 가정을 사용한다

- **Proximity and Continuity**: 입력 공간과 학습된 피쳐 공간 모두에서 서로 가까운 지점은 같은 레이블을 공유할 가능성이 더 높다고 본다
- **Robust feature**는 DNN의 은닉층 내에서 학습이 되고, 정상과 이상 데이터 포인트를 구분하는 **discriminative 속성**을 유지한다고 본다.

**Computational Complexity** 

Semi-supervised DAD 기반 기술의 계산 복잡성은 주로 representative 피쳐 학습을 위해 사용된 입력 데이터의 차원 및 은닉층의 수에 의존적이다.

**Advantages**

- 적은 레이블 된 데이터로도 학습 가능한 Generative Adversarial Networks (GANs)을 사용 가능
- 레이블 된 데이터 (일반적으로 하나의 클래스)를 사용하면 unsupervised 방식보다 더 나은 성능을 제공

**Disadvantages**

- overfitting: 은닉층에서 추출된 hierachical 피쳐들이 이상(anomal) 인스턴스에 대한 representative 가 없을 수 있음



 ## 3. Hybrid Deep Anomaly Detection

Hybrid DAD 에서는 DL 모델을 robust 피쳐 추출하는 추출기 (feature extractor)로 사용하고, 추출된 피쳐를 전통 ML 분류 알고리즘 (e.g. one-class RBF, SVM) 에 입력으로 사용한다. 

**Assumptions**

- 피쳐 추출기가 은닉층에서 robust 피쳐를 추출하여 이상 값이 감춰지지 않도록 불필요한 특성을 분리하는 데 도움이 된다. 
- 복잡한 고차원 공간에서 강력한 이상 탐지 모델을 만들기 위해, 피쳐 추출기와 이상 탐지기가 필요하다.

**Computational Complexity** 

피쳐 추출기와 전통 알고리즘의 복잡도를 모두 포함한다. <br/>
딥 레이어를 사용하는 경우 최적의 매개변수를 찾아야 되어 복잡도가 높다. <br/>
선형 SVM과 같은 고전적인 알고리즘의 경우, 입력 차원 수 $d$ 에 따른 복잡도는 $O(d)$ 이지만.  Polynomial, RBF 등의 대부분의 커널에서는, support vector $n$ 에 따라, $O(nd)$ 의 복잡도를 갖는다.

**Advantages**

- 차원의 저주 (curse of dimentionality)를 피할 수 있음 
- 줄어든 입력 차원에서 커널 모델들이 동작하므로, 효율적 

**Disadvantages**

- 피쳐추출에서 이상 탐지를 위한 맞춤형 objective 함수를 사용하지 않아서 부적합할 수 있음
- 개별 레이어가 사전 훈련된 경우, deep 한 hybrid 모델이 더 잘 수행되지만, 이는 계산 비용이 높음





## 4. One-class Neural Networks (OC-NN) for Anomaly Detection 

OC-NN은, DNN가 데이터의 점진적으로 풍부한 representative을 추출하는 능력과 hyperplane 또는 와 같은 one-class objective를 결합하여 모든 정상 데이터 포인트를 이상 값으로부터 분리하는 능력을 갖는다. 이 방식은 이상 탐지에 대한 맞춤형 objective 함수를 최적화하여 학습된 은닉층의 데이터 representative을 학습한다는 점이 특징이다.

**Assumptions**

- OC-NN 모델은 DNN의 hidden layer 내에서 데이터 분포의 common factor를 추출한다.
- 결합된 representation 학습을 수행하고, 테스트 데이터 인스턴스에 대한 outlier 스코어를 생성한다.
- 이상 샘플들은 common factor 가 포함되어 있지 않으므로, 은닉층에서 이상 값의 representation을 파악하지 못한다.

**Computational Complexity**

OC-NN 모델의 연산 복잡성은 선택한 DNN의 복잡성에 의존적이다

**Advantages**

- OC-NN 모델은 데이터를 둘러싸는 hyperplane 또는 hypersphere을 최적화 하면서, 동시에 DNN을 학습



## 5. Unsupervised Deep Anomaly Detection 

Unsupervised DAD에 대한 다양한 DL 프레임워크들이 제안되었으며, 이 중 오토인코더 (Autoencoder)가 이상치 탐지에 사용되는 기본적인 unsupervised deep 아키텍처이다.

 **Assumptions**

- 원본 또는 어떤 잠재적인 특징 공간에서 "정상" 영역은 "이상" 영역과 구별될 수 있다. 
- 대부분의 데이터 인스턴스는 데이터셋의 다른 부분(이상)에 비해 정상이다. 
- Unsupervised 이상치 탐지 알고리즘은 데이터 집합의 내재적인 속성(거리, 밀도 등)에 기초하여 데이터 인스턴스의 이상치 점수를 생성한다. <br/>
  DNN 의 은닉층은 데이터 집합 내의 이러한 내재적인 속성을 파악할 수 있다.

**Computational Complexity**

Quadratic cost를 갖으며, non-convex 최적화를 수행한다. <br/>
모델의 계산 복잡도는 연산 수, network 파라미터, 은닉 층 수 에 depend 하다. 이 방식은, PCA 와 같은 전통적 방법보다는 훨씬 높은 복잡도를 보인다.

**Advantages**

- 레이블링이 필요 없음

**Disadvantages**

- 복잡, 고차원 공간에서 데이터의 common factor를 학습하는 것이 어려움 
- Noise와 data corruption에 민감하고, 다른 방식보다 정확성이 떨어짐





## 6. 그 외 기술

### 6.1 Transfer Learning based Anomaly Detection

전이 학습 (transfer learning)은 데이터 의존성을 완화하고 제한된 학습 데이터 인스턴스로 좋은 성능을 얻을 수 있도록 도와준다. 전이 학습은 학습 데이터와 미래 데이터가 동일한 피쳐 공간에 있고 동일한 분포를 가져야 한다는 가정을 완화하여 소스 도메인에서 타겟 도메인으로 지식을 전달할 수 있는 ML 기술이다. 전이 표현 학습은 여러 연구에서 유망한 결과를 보였다. ([^1] 논문 참고)

### 6.2 Zero Shot Learning based Anomaly Detection

제로샷 러닝 (Zero Shot Learning)은 훈련 세트에서 본 적이 없는 object 를 인식하는 것을 목표로 한다. 이를 위해 두 단계로 이루어진다. <br/>
(1) 객체에 대한 지식이 자연어 설명이나 속성(메타데이터)로 파악된다. <br/>
(2) 이러한 지식이 새로운 클래스의 인스턴스를 분류하는 데 사용된다. 
이러한 방식은 훈련에서 모든 가능한 클래스의 이미지를 얻지 못할 수 있는 실제 세계에서 중요하다. <br/>
이 접근 방식과 관련된 주요 첼린지는 데이터 인스턴스에 대한 메타데이터 획득이다. 
제로샷 러닝을 사용하여 이상 탐지 및 독창성 탐지를 수행하는 몇 가지 연구 들이 좋은 결과를 보였다.  ([^1] 논문 참고)

### 6.3 Ensemble based Anomaly Detection

DNN의 문제점 중 하나는 noise에 민감하며, robust 한 성능을 보이려면 대량의 학습 데이터가 필요하다. <br/>이러한 문제를 극복하기 위해, 자동 인코더의 연결 아키텍처를 랜덤하게 변화시켜 앙상블을 구성하는 방법을 사용할 수 있다. 앙상블 방식은 다양성을 증가시켜 overfitting 문제를 피하면서 학습 시간을 단축시킬 수 있다.

### 6.4 클러스터링 기반 이상 감지: 

클러스터링은 특징을 추출하여 유사한 패턴을 그룹으로 묶는 방식으로 이루어지며, 이를 이용하여 새로운 이상을 감지한다. <br/>
클러스터링 기반 이상 감지는 클래스 수가 증가함에 따라 시간 및 공간 복잡도가 선형적으로 증가하기 때문에 real-time application 에는 적합하지 않다. <br/>
DNN 은닉층에서 피쳐를 추출하여 입력 데이터의 차원을 줄여서, 복잡하고 고차원 데이터셋에 대한 확장성(scalability)을 보장하는 클러스터링 기반 이상 탐지가 제시되고 있다.



 

> References

[^1]: Chalapathy, Raghavendra, and Sanjay Chawla. "Deep learning for anomaly detection: A survey." *arXiv preprint arXiv:1901.03407* (2019)
