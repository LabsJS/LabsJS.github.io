---
title : "One-Class Adversarial Networks"
excerpt : ""
toc: true
toc_sticky: true
categories :
 - Anomaly Detection
tags:
 - OCAN
 - GAN
 - AE
 - LSTM
---

## OCAN: One-Class Adversarial Networks

OCAN [^1]는 sequencial data에 대한 이상 점수 (anomaly score)를 구하는 것을 objective 로 한 방법이다. 

Semi-supervised learning 방식을 사용하며, 정상 데이터만으로도 모델 학습이 가능한 방법이다.  



### Advantages of OCAN

- 이상 데이터에 대한 정보를 필요로 하지 않는다.
- Complementary sample 을 생성한다. 
  : 이 sample 은 정상 / 이상 데이터를 더 잘 분리하는데 사용할 수 있다.
- Sequential data에 대한 정를 파악할 수 있다



### OCAN Framework

OCAN 는 2개의 phase 로 이상 점수를 계산한다.

- 첫번째 phase에서는 LSTM-Autoencoder 아키텍처를 사용한다. 
  Sequence-to-Sequence 로 모델로, 두개의 LSTM 이 각각 인코더, 디코더가 된다.
  이를 통해 data에 대한 표현(representation)을 구한다. (인코더의 결과) 

- 두번째 phase에서는 complementary GAN (CGAN) 을 사용한다. 
  첫번째 phase로 구한 표현에 대해서 CGAN의 구별자(discriminator)로 이상 유무를 감지한다. 

<img src="https://www.researchgate.net/profile/Panpan-Zheng-4/publication/323571011/figure/fig1/AS:601023542484992@1520306587073/The-training-framework-of-OCAN.png" alt="OCAN " style="zoom:50%;" />

OCAN 의 학습 알고리즘은 다음과 같다.
$$
\begin{array}{l}
\textbf { Inputs :}\text{ Training dataset } M_{\text {benign }}=\left\{\mathcal{X}_{1}, \cdots, \mathcal{X}_{N}\right\} \text {, } \\
\quad \text { Training epochs for LSTM-Autoencoder } \\
\quad \text { Epoch}_{AE} \text { and GAN Epoch }_{G A N} \\
\textbf { Outputs :}\text{ Well-trained LSTM-Autoencoder and complementary GAN } \\
\\
\text { initialize parameters in LSTM-Autoencoder and complementary GAN; } \\
\\
\textbf{while } j< \text{ Epoch } _{A E} \textbf{ do}\\
\quad \textbf{foreach}  \text{ user u in } M_{\text {benign }} \textbf{ do}\\
\quad \quad \text{compute the reconstructed sequence of user activities}\text{ by LSTM-Autoencoder (Eq. 1, 3, and 4);}\\
\quad \quad \text{optimize the parameters in LSTM-Autoencoder with}\text{ the loss function Eq. 5;}\\
\quad \textbf{end}
\quad j \larr j+1;
\\
\\


\mathcal{V}=\emptyset \\
\textbf {foreach}\text{ user } u \text { in } M_{\text {benign }} \textbf { do }\\
\quad\text { compute the benign user representation } \mathrm{v}_{u} \text { by the encoder of LSTM-Autoencoder (Eq. } 1,2); \\
\quad\mathcal{V}+=v_{u} \text {; } \\
\textbf {end } \\
\\

j \leftarrow 0 ; \\
\textbf {while } j<\text { Epoch }_{G A N} \textbf { do } \\

\quad \textbf { foreach }\text{benign user representation } \mathrm{v}_{u} \text { in } \mathcal{V} \textbf { do } \\
\quad \quad \text { optimize the discriminator } D \text { and generator } G \text { with loss } \\
\quad \textbf {end }\\
\textbf {end }\\
\textbf{return}\text{ well-trained LSTM-Autoencoder and complementary GAN}\\

\end{array}
$$

- 주어진 학습 데이터는 N 개의 피쳐 벡터 인스턴스이다
- 우선 LSTM-Autoencoder 모델을 학습한다
- 학습 후에 LSTM-Autoencoder 의 인코더를 사용해 정상 데이터에 대한 표현을 계산한다
- 정상 데이터 표현을 사용해 CGAN 을 학습한다. 



일반 GAN (regular GAN)에서 생성자는 실제 데이터와 가까운 가짜 데이터를 생성하는 것을 목표로한다.

구별자는 실제와 가짜 데이터를 구별하는 것을 목표로 한다

이 방식의 단점으로는, 구별자가 수렴하게 되면, 정상과 비정상 데이터를 분리하는 것에 대한 높은 신뢰도를 갖지 못한다는 것이다. 때문에 OCAN에서는 CGAN 을 사용하는 방식을 제안하였다.





#### LSTM-Autoencoder

OCAN 의 첫번째 페이즈에서는 데이터를 연속적인 히든 스페이스에 인코드한다. 

입력이 sequence 데이터이기 때문에 LSTM 을 사용한다. 이로써 가변 길이의 데이터를 고정된 차원의 표현으로 변환할 수 있다.

하나의 시퀀스 데이터 인스턴스는 다음과 같이 표현한다. (T개로 구성된 시퀀스)
$$
\mathcal{X}_{u}=\left(\mathrm{x}_{1}, \ldots, \mathrm{x}_{t}, \ldots, \mathrm{x}_{T}\right)
$$
여기서 $\mathrm{x}_i$ 는 d 의 차원을 가진 피쳐 벡터이다.

**Encoder:** 시퀀스 데이터 $$\mathcal{X}_u$$ 는 다음 수식과 같이 LSTM 을 사용해 인코딩 된다.  

$$\mathbf{h}_{t}^{e n}=\operatorname{LSTM}^{e n}\left(\mathbf{x}_{t}, \mathbf{h}_{t-1}^{e n}\right)$$	 (1)

$$\mathbf{h}_{t}^{e n}$$ 는 t 번째 히든 벡터를 가리킨다.

마지막 히든 벡터 $$\mathbf{h}_{T}^{e n}$$ 는 시퀀스의 전체적인 정보를 파악한다. 이를 표현(representation) 으로 사용한다. 

$$\mathbf{v}=\mathbf{h}_{T}^{e n}$$ 	(2)

**Decoder:** 디코더는 입력 v 를 시퀀스 데이터 $$\mathcal{X}$$ 로 재구성한다.

$$\mathbf{h}_{t}^{d e} =L S T M^{d e}\left(\mathbf{v}, \mathbf{h}_{t-1}^{d e}\right)$$	 (3)

$$\hat{\mathbf{x}}_{t} =f\left(\mathbf{h}_{t}^{d e}\right)$$	 (4)

여기서 $$\mathbf{h}_{t}^{d e}$$ 는 디코더의 t 번째 히든 벡터이다. 

$$\hat{\mathbf{x}}_{t}$$ 는 재구성된 t 번째 피쳐 벡터를 기리킨다

$$f$$ 는 신경망을 가리키고, 디코더의 히든벡터로 부터 시퀀스 출력을 계산한다.



LSTM-Autoencoder 의 objective 함수는 다음과 같다.
$$
\mathcal{L}_{(A E)}\left(\hat{\mathbf{x}}_{t}, \mathbf{x}_{t}\right)=\sum_{t=1}^{T}\left(\hat{\mathbf{x}}_{t}-\mathbf{x}_{t}\right)^{2} \quad \text{(5)}
$$


#### Complementary GAN

CGAN 의 생성자 G는 표현 v 와 같은 차원을 가진 출력 레이어를 갖는다. ($$\tilde{\mathbf{v}}=G(\mathbf{z})$$)

일반적인 GAN 에서는 데이터의 표현 $$p_{data}$$에 대한 분포를 학습하는 것이지만, CGAN 에서는 다음과 같은 complementary 분포 $$p^*$$ 를 학습한다.
$$
p^{*}(\tilde{\mathbf{v}})=\left\{\begin{array}{ll}
\frac{1}{\tau} \frac{1}{p_{\text {data }}(\overline{\mathbf{v}})} & \text { if } p_{\text {data }}(\tilde{\mathbf{v}})>\epsilon \text { and } \tilde{\mathbf{v}} \in \mathcal{B}_{\mathbf{v}} \\
C & \text { if } p_{\text {data }}(\tilde{\mathbf{v}}) \leq \epsilon \text { and } \tilde{\mathbf{v}} \in \mathcal{B}_{\mathbf{v}},
\end{array}\right.
$$
여기서 $$\epsilon $$ 는 임계값으로, 생성된 샘플이 고밀도 지역에 있는지 여부를 가리킨다.



$$\tau$$ 는 정규화 텀이다. 

$$C$$ 는 상수이다.

$$ \mathcal{B}_{\mathbf{v}}$$ 는 데이터 표현의 공간이다. 

생성 분포 PG 가 complementary 분포 $$p^*$$ 에 가깝게 하기 위해서 

생성자는 KL divergence 를 사용한다. 

이에 관한 objective 함수는 다음과 같다.
$$
\begin{aligned}
\mathcal{L}_{K L\left(p_{G} \| p^{*}\right)} & =-\mathcal{H}\left(p_{G}\right)-\mathbb{E}_{\tilde{\mathbf{v}} \sim p_{G}} \log p^{*}(\tilde{\mathbf{v}}) \\
& =-\mathcal{H}\left(p_{G}\right)+\mathbb{E}_{\tilde{\mathbf{v}} \sim p_{G}} \log p_{\text {data }}(\tilde{\mathbf{v}}) \mathbb{1}\left[p_{\text {data }}(\tilde{\mathbf{v}})>\epsilon\right] \\
& +\mathbb{E}_{\tilde{\mathbf{v}} \sim p_{G}}\left(\mathbb{1}\left[p_{\text {data }}(\tilde{\mathbf{v}})>\epsilon\right] \log \tau-\mathbb{1}\left[p_{\text {data }}(\tilde{\mathbf{v}}) \leq \epsilon\right] \log C\right),
\end{aligned}
$$
여기서 $$\mathcal{H}$$ 는 엔트로피이고, $$ \mathbb{1} $$은 indicator 함수이다. 

마지막 텀에서 $$\tau, C$$은 생략될 수 있다. 이들은 상수항이고, 생성자에서 해당 파라미터들의 그레이디언트는 거의 0이기 때문이다.  



이에 덧붙여서 생성자는 다음과 같은 feature matching loss[1] 를 사용한다. (생성자의 학습 안정성을 위함)
$$
\mathcal{L}_{\mathrm{fm}}=\left\|\mathbb{E}_{\tilde{\mathbf{v}} \sim p_{G}} f(\tilde{\mathbf{v}})-\mathbb{E}_{\mathbf{v} \sim p_{\text {data }}} f(\mathbf{v})\right\|^{2}
$$
여기서 f 는 구별자의 중간 레이어의 출력이다.  



생성자의 전체 objective 함수는 다음과 같다.
$$
\begin{aligned}
\min _{G} & -\mathcal{H}\left(p_{G}\right)+\mathbb{E}_{\tilde{\mathbf{v}} \sim p_{G}} \log p_{\text {data }}(\tilde{\mathbf{v}}) \mathbb{1}\left[p_{\text {data }}(\tilde{\mathbf{v}})>\epsilon\right] \\
& +\left\|\mathbb{E}_{\tilde{\mathbf{v}} \sim p_{G}} f(\tilde{\mathbf{v}})-\mathbb{E}_{\mathbf{v} \sim p_{\text {data }}} f(\mathbf{v})\right\|^{2}
\end{aligned}
$$
이를 통해 생성자는 생성분포 $$p_G$$ 를 $$p^*$$ 에 가까워지도록 학습된다. 



다음 그림은 일반 GAN 과 CGAN 의 차이를 보여준다. 

CGAN의 generator 는 $$p^*$$ 를 목표로 학습하기 때문에, 고밀도 밖($$\epsilon$$)의 공간에 데이터를 생성하게 된다.



생성자의 objective 함수를 최적화 하기 위해, 생성된 샘플 $$\mathcal{H}(p_G)$$ 의 엔트로피와, 실제 샘플 $$p_{data}$$ 의 확률 분포를 추정해야 한다. 

$$\mathcal{H}(p_G)$$ 는 [3,4] 에서 제시한 **pull-away term** (PT)을 사용해 추정한다: 이는 생성된 피쳐 벡터가 orthogonal 해지도록 돕는다. 

PT 텀은 생성되는 샘플의 다양성을 증가시키고, $$-\mathcal{H}(p_G)$$ 를 최소화 하는 proxy 가 될 수 있다. 

PT 텀은 다음과 같이 정의된다. 
$$
\mathcal{L}_{P T}=\frac{1}{N(N-1)} \sum_{i}^{N} \sum_{j \neq i}^{N}\left(\frac{f\left(\tilde{\mathbf{v}}_{i}\right)^{T} f\left(\tilde{\mathbf{v}}_{j}\right)}{\left\|f\left(\tilde{\mathbf{v}}_{i}\right)\right\|\left\|f\left(\tilde{\mathbf{v}}_{j}\right)\right\|}\right)^{2}
$$
여기서 $$N$$ 은 미니배치 크기이다. 

실제 샘플의 데이터 분포 $$p_{data}$$ 는 일번적으로 사용하기 어렵고, $$p_{data}$$를 근사하는데 계산 비용이 많이 든다. 

그래서 여기서는 [5] 에서 제시한 판별자를 사용한다. 

이는 데이터가 실제 분포에서 왔는지, 생성된 분포에서 왔는지 감지할 수 있다.

기본 컨셉은 판별자는 샘플이 생성자 실제 정상 데이터와 가까운 샘플들을 생성하도록 학습했을 때, 실제 데이터와 생성된 데이터를 구분할 수 있다는 것이다. 

그래서 판별자는 학습과정에서 $$p_{data}$$ 의 임계값 위에 있는 데이터 포인트들을 충분히 식별할 수 있다고 본다.



일반 GAN 모델을 개별적으로 학습하고, 그 판별자를 사용해서 pdata(~v) > e 를 평가하기 위한 proxy 로 사용한다





판별자 $$D$$ 는 정상 데이터 표현 $$\mathbf{v}$$ 와 생성된 표현 $$ \tilde{\mathbf{v}}$$ 를 입력으로 받고 이 둘을 구별한다. 

classifier 로서 D 는 softmax 를 가진 표준 feedforward NN 을 사용한다. 

D의 objective 함수는 다음과 같다.
$$
\begin{aligned}
\max _{D} \  & \mathbb{E}_{\mathbf{v} \sim p_{\text {data }}}[\log D(\mathbf{v})]+\mathbb{B}_{\tilde{\mathbf{v}} \sim p_{G}}[\log (1-D(\tilde{\mathbf{v}}))]+
 \mathbb{E}_{\mathbf{v} \sim p_{\text {data }}}[D(\mathbf{v}) \log D(\mathbf{v})] .
\end{aligned}
$$


첫번째 텀은 일반 GAN 모델의 objective 함수이다. 그래서 CGAN 의 판별자는 정상데이터와 complementary sample 을 구분한다. 

마지막 텀은 조건부 엔트로피 텀이다. 이는 판별자가 높은 신뢰도를 갖고 실제 정상 데이터를 감지할 수 있도록 한다. 이를 통해 판별자는 정상과 이상 데이터를 명확하게 분리할 수 있다.



regular GAN 과 CGAN 의 구별자의 objective 는 유사하지만, 이상 탐지에 대한 능력에는 차이가 있다.

일반 GAN 의 식별자는, 정상과 생성된 데이터를 분리하도록 학습하지한다. 

그러나 학습 후에 생성된 데이터는 실제 데이터와 같은 지역에 위치하게 된다. 

때문에 정상 데이터가 주어지더라도 판별자가 높은 신뢰도록 구별하기는 어렵다. 

반면데 CGAM 의 판별자는 실제 정상 데이터와 생성된 데이터를 분리하기 위해 학습된다. 

그래서 생성된 데이터는 이상 데이터의 분포와 같아지게 되며, 판별자가 이상 데이터 또한 탐지할 수 있게 된다. 





#### Fruad Detection Model

Faud 감지 모델은 e2e 모델이다. 알고리즘은 다음과 같으며, 그림의 구조를 갖는다. 
$$
\begin{array}{l}\textbf{Inputs :}\text{ Testing dataset } M_{\text {test }}=\left\{X_{1}, \cdots, X_{N}\right\} \text{,}\\
\quad \text{Well-trained LSTM-Autoencoder and GAN}\\
\textbf{Outputs :}\text{ the user labels } \mathcal{Y} \text{ in } M_{\text {test }}
\\
\mathcal{Y}=\emptyset;\\
\textbf{foreach }\text{user } u \text{ in } M_{\text {test }} \textbf{ do}\\
\quad \text{compute the user representation } \mathbf{v}_{u} \text{ by the encoder in}\text{ LSTM-Autoencoder (Eq. 6, 7);}\\
\quad \text{predict the label } \hat{y}_{u} \text{ of the user by } D\left(\mathbf{v}_{u}\right)\\
\quad \mathcal{Y}_{+}=\hat{y}_{u}\\
\textbf {end }\\
\textbf{return}\text{ the user labels }\mathcal{Y}

\end{array}
$$


<img src="https://www.researchgate.net/profile/Panpan-Zheng-4/publication/323571011/figure/fig3/AS:601023542489088@1520306587551/The-fraud-detection-model.png" alt="fraud detection model" style="zoom:50%;" />

이상 탐지를 위해, 우선 인코더를 사용해 representation $$\mathbf{v}_u$$를 계산한다. 그리고 CGAN 의 판별자를 사용해 label 을 예측한다. 



**Early fraud detection**

OCAN 은 이상 데이터에 대해 early detection 도 가능하다. u 와 step t 가 주어졌을 때, 히든 state 는 t 번째 스텝까지 업데이트 된다. 

이는 t 번째 스텝까지의 행동 정보를 파악할 수 있다.

그렇기 때문에 t 번째 스텝에서의 표현은 $$ \mathbf{v}_{u_t}$$로 표기될 수 있다. 

여기서, 판별자 $$D$$ 를 사용해서 확률 $$p\left(\hat{y}_{u_{t}} \mid \mathbf{v}_{u_{t}}\right)=D\left(\mathbf{v}_{u_{t}}\right)$$를 계산하고 이상 유무를 판별한다. 





> References

[^1]: Panpan Zheng, Shuhan Yuan, Xintao Wu, Jun Li, and Aidong Lu. 2019. One-class adversarial nets for fraud detection. In AAAI. 1286–1293.
[^2]: Tim Salimans, Ian Goodfellow, Wojciech Zaremba, Vicki Cheung, Alec Radford, and Xi Chen. 2016. Improved Techniques for Training GANs. arXiv:1606.03498 [cs] (2016).
[^3]: Zihang Dai, Zhilin Yang, Fan Yang, William W. Cohen, and Ruslan Salakhutdinov. 2017 Good Semi-supervised Learning that Requires a Bad GAN. In NIPS.
[^4]: Junbo Zhao, Michael Mathieu, and Yann LeCun. 2016. Energy-based Generative Adversarial Network. arXiv:1609.03126 [cs, stat] (2016).
[^5]: Liam Schoneveld. 2017. Semi-Supervised Learning with Generative Adversarial Networks. Ph.D. Dissertation.
