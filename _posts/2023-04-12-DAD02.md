---
title : "Deep Anomaly Detection (2)"
excerpt : "Taxonomy"
toc: true
toc_sticky: true
categories :	
 - Anomaly Detection
---
> 본 포스팅에서는 이상 탐지 조사 논문[^1],[^2] 을 참고 하여,
> 딥러닝 기반 이상 탐지 기술에 대한 taxonomy를 다룬다.



## 1. 입력 데이터의 성격에 따른 분류 (Nature of Input Data) 

DL 기반 이상 탐지 방법에서 딥러닝 아키텍처를 선택하는 것은 입력 데이터의 **성격(nature)**에 따라 달라진다. 
입력 데이터는 **sequential 데이터**(음성, 텍스트, 음악, 시계열 등) 또는 **non-sequential 데이터**(예: 이미지, 기타 데이터)로 분류될 수 있고,<br/>각 분류는 다음과 같은 아키텍쳐를 주로 사용한다.

- Sequential data: CNN, RNN, LSTM
- Non-sequential data: CNN, AE 

추가로, **feature의 수**에 따라 입력 데이터는 저차원 데이터 또는 고차원 데이터로 분류될 수 있다. <br/>고차원의 입력 데이터 내에서 복잡한 계층적 feature 관계를 학습하기 위해 **Deep Anomaly Detection (DAD)** 기술이 사용된다. <br/>DAD 기술에서 사용되는 layer 의 수는 입력 데이터의 차원에 따라 결정되며, 더 deep 한 네트워크는 고차원 데이터에서 더 나은 성능을 보인다.  (LeCun 2015)



## 2. 레이블 가용성에 따른 분류 (Availability of Labels) 

DAD 모델은 **레이블(label)**의 **가용성(Availability)**에 따라 크게 세 가지 범주로 분류된다. 

### 2.1. Supervised deep anomaly detection

Supervised DAD는 일반적으로 **정상(normal) 및 이상(outlier or anormal) 데이터 인스턴스(data instance)의 레이블**을 사용하여 deep supervised binary 또는 multi-class 분류기를 훈련하는 것을 말한다. <br/>
이 방식은 **레이블된 학습샘플 (training sample)의 부족**으로 인해 unsupervised 나 semi-supervised 방법에 비해 사용이 적다. <br/>
또한 이상 탐지에 사용되는 분류기의 성능은 **클래스 불균형**으로 인해 최적화가 어렵다.

### 2.2. Semi-supervised deep anomaly detection

Semi-supervised DAD는 일반적으로 정상 인스턴스의 레이블이 이상치보다 쉽게 얻어져서 많이 사용된다. <br/>
**Deep autoencoder**를 활용하는 방법 중 하나로, 이상치가 없는 데이터 샘플에서 unsupervised 방식으로 학습시킬 수 있다. <br/>
충분한 학습샘플 이 있는 경우, 정상 클래스의 Autoencoder는 정상적인 인스턴스에 대해 낮은 reconstruction error를 생성한다. <br/>

### 2.3. Unsupervised deep anomaly detection

Unsupervised DAD는 데이터의 내부적인 특성만을 사용해서 이상치를 감지하는 방법이다. <br/>
레이블이 없는 데이터 샘플에 대한 자동 레이블링에 많이 사용되며, 레이블된 데이터를 얻기 어려울 때 적합하다. <br/>
모든 Unsupervised DAD 모델의 핵심은 Autoencoder이다. 이러한 모델은 정상적인 데이터 인스턴스보다 이상 데이터 인스턴스가 훨씬 적다고 가정하며, 그렇지 않으면 높은 false posotive를 보인다. <br/>
이상치를 감지하기 위해 사용되는 비지도 학습 알고리즘으로는 Restricted Boltzmann Machine (RBM), Deep Boltzmann Machine (DBM), Deep Belief Network (DBN), genealized denoising autoencoder, RNN, LSTM 이 있다.



## 3. 학습 objective에 따른 분류 (Training Objective)

### 3.1 Deep Hybrid Model (DHM)

이상 탐지를 위한 DHM은 주로 오토인코더와 같은 Deep Neural Networks (DNN)를 **피쳐 추출기(feature extractor)**로 사용 한다. <br/>
오토인코더의 hidden representation 내에서 학습된 피쳐는 일반적인 이상 탐지 알고리즘인 One-Class SVM (OC-SVM)와 같은 모델에 입력하여 이상치를 감지한다.<br/>
다음 그림 은 이상 탐지에 사용되는 DHM 아키텍처이다. 

![Deep Hybrid Model Architecture.](/assets/img/2023-04-14-DAD02/Deep-Hybrid-Model-Architecture.png)



[3] 에서는 하이브리드 모델이 **전이 학습(transfer learning)**을 사용하여 피쳐 추출기의 좋은 성능을 보였다. <br/>
[4] 에서는 **피쳐 추출기와 OC-SVM (or SVDD) objective를 같이 학습**하는 하이브리드 모델의 variants를 제안하였다<br/>

이러한 방법은 **이상 탐지에 맞춰진 훈련 가능한 objective 가 부족**하다는 단점이 있다. 
때문에 피쳐가 **정상과 이상치 사이의 차이를 반영**하기가 어렵다. <br/>
이를 극복하기 위해, Deep one-class classification [^5], One class neural networks [^6] 과 같이 이상 탐지를 위한 objective 가 도입되었다

### 3.2 One-Class Neural Networks (OC-NN)

 OC-NN은 딥 네트워크가 점진적으로 데이터를 rich representation으로 추출하는 능력과, 정상 데이터 주위에 타이트한 경계를 생성하는 one-class 의 objective를 합쳤다. hidden layer에서의 데이터 representation은 OC-NN objective에 의해 결정되어, 이상 탐지에 적합하다. <br/>
이 외에 Deep Support Vector Data Description (Deep SVDD) [^5]는 정상 데이터 인스턴스를 sphere의 중심에 가깝게 매핑하여 변화의 공통 요소를 추출하도록 Deep NN을 훈련시키는 방법을 제안했다. 아키텍쳐 관련 상세내용은 다음 포스팅에서 제공한다.



### 4. 출력에 따른 분류 (Output of DAD Techniques)

### 4.1 Anomaly Score

이상 점수(anomaly score)는 각 데이터 포인트의 이상 여부를 나타내는 지표이다. <br/>
데이터 인스턴스는 이상 점수에 따라 순위가 매겨지며, 일반적으로 결정 점수 (decision score)라고하는 도메인별 임계값을 선택하여 이상을 구분한다. <br/>
예를 들어, Deep SVDD 방법에서 데이터 포인트와 sphere의 중심 사이의 거리 측정값을 결정 점수로 사용하고, sphere의 중심에서 멀리 떨어진 데이터 포인트를 이상으로 간주한다.<br/>

### 4.2 Label 

일반적으로 각 데이터 인스턴스에 대해 정상 또는 이상의 카테고리 레이블을 할당하는 방식을 사용한다. <br/>
오토인코더를 사용한 비지도 이상 탐지 기술은 residual 벡터의 크기를 측정하여 이상 점수를 얻고, 해당 도메인 전문가가 결정한 도메인별 임계값을 지정하여 재구성 오류를 레이블로 지정한다.

## 5. 모델링 관점에서의 분류 (Modeling)



Deep Anomaly Detection (DAD)는 모델링 관점에서 아래 그림과 같이 3개의 주요 카테고리와, 11개의 세부 카테고리로 나눌 수 있다.

<img src="/assets/img/2023-04-14-DAD02/image-20230418094441252.png" alt="image-20230418094441252" style="zoom:80%;" />

DAD는 세가지 주요 페러다임, "Deep learning for feature extraction", "Learning feature representations of normality", "End-to-end anomaly score learning" 으로 구분될 수 있다. 첫번째의 경우, 딥러닝 기술이 피처 추출을 위해서만 사용되는 것이고, 두번째는 딥러닝과 이상 탐지가 어느정도의 의존 관계를 갖으며 학습이된다. 
세번째는 딥러닝과 이상탐지가 완전히 통합된 형태이다. <br/>
세부 내용은 이후 포스팅에서 다룬다.





> References

[^1]: Chalapathy, Raghavendra, and Sanjay Chawla. "Deep learning for anomaly detection: A survey." *arXiv preprint arXiv:1901.03407* (2019).
[^2]: Pang, Guansong, et al. "Deep learning for anomaly detection: A review." *ACM computing surveys (CSUR)* 54.2 (2021): 1-38.
[^3]: Sinno Jialin Pan, Qiang Yang, et al. A survey on transfer learning. IEEE Transactions on knowledge and data engineering, 22(10):1345–1359, 2010. 
[^4]: Tolga Ergen, Ali Hassan Mirza, and Suleyman Serdar Kozat. Unsupervised and semi-supervised anomaly detection with lstm neural networks. arXiv preprint arXiv:1710.09207, 2017
[^5]: Lukas Ruff, Nico Gornitz, Lucas Deecke, Shoaib Ahmed Siddiqui, Robert Vandermeulen, Alexander Binder, ¨ Emmanuel Muller, and Marius Kloft. Deep one-class classification. In ¨ International Conference on Machine Learning, pages 4390–4399, 2018.
[^6]:  Raghavendra Chalapathy, Aditya Krishna Menon, and Sanjay Chawla. Anomaly detection using one-class neural networks. arXiv preprint arXiv:1802.06360, 2018. 
